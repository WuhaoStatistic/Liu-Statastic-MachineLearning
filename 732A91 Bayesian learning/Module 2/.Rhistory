{
if((estimated[i]-threshold)*(estimated[i+1]-threshold)<0)
{
index=c(index,i)
}
}
interval = c(d$x[index[1]],d$x[index[2]])
d=density(Gini_coe)
estimated = d$y
sort_estimated = sort(estimated)
threshold = sort_estimated[floor(length(sort_estimated)*0.05)]
index = c()
for (i in 1:(length(sort_estimated)-1))
{
if((sort_estimated[i]-threshold)*(sort_estimated[i+1]-threshold)<0)
{
index=c(index,i)
}
}
interval = c(d$x[index[1]],d$x[index[2]])
d=density(Gini_coe)
estimated = d$y
sort_estimated = sort(estimated)
threshold = sort_estimated[floor(length(sort_estimated)*0.05)]
index = c()
for (i in 1:(length(sort_estimated)-1))
{
if((sort_estimated[i]-threshold)*(sort_estimated[i+1]-threshold)<0)
{
index=c(index,i)
}
}
interval = c(d$x[index[1]],d$x[index[2]])
sort_estimated
d=density(Gini_coe)
estimated = d$y
sort_estimated = sort(estimated)
threshold = sort_estimated[floor(length(sort_estimated)*0.05)]
index = c()
for (i in 1:(length(sort_estimated)-1))
{
if((sort_estimated[i]-threshold)*(sort_estimated[i+1]-threshold)<0)
{
index=c(index,sort_estimated[i])
}
}
interval = c(d$x[index[1]],d$x[index[2]])
print(interval)
d[["x"]]
d$x
d$x[1]
d=density(Gini_coe)
estimated = d$y
sort_estimated = sort(estimated)
threshold = sort_estimated[floor(length(sort_estimated)*0.05)]
interval=c()
for (i in 1:(length(d$x)-1))
{
if((d$y[i]-threshold)*(d$y[i+1]-threshold)<=0)
interval=c(interval,d$x[i])
}
print(interval)
d=density(Gini_coe)
estimated = d$y
sort_estimated = sort(estimated)
threshold = sort_estimated[floor(length(sort_estimated)*0.05)]
interval=c()
for (i in 1:(length(d$x)-1))
{
if((d$y[i]-threshold)*(d$y[i+1]-threshold)<=0)
interval=c(interval,d$x[i])
}
print(interval[1:2])
install.packages('besselI')
?besselI
d = c(1.83,2.02,2.33,-2.79,2.07,2.02,-2.44,2.14,2.54,2.23)
k = (1:1000)/100
mu = 2.51
res = exp(k*sum(cos(d-mu))-k)/besselI(x = k, nu=0)^n_radians
d = c(1.83,2.02,2.33,-2.79,2.07,2.02,-2.44,2.14,2.54,2.23)
k = (1:1000)/100
mu = 2.51
res = exp(k*sum(cos(d-mu))-k)/besselI(x = k, nu=0)^length(d)
df = data.frame(k=k,val=res)
p6 = ggplot(df, aes(x=k, y=val))+
geom_line()+
ggtitle('distribution of posterior k')
print(p6)
d = c(1.83,2.02,2.33,-2.79,2.07,2.02,-2.44,2.14,2.54,2.23)
k = (1:1000)/100
mu = 2.51
res = exp(k*sum(cos(d-mu))-k)/besselI(x = k, nu=0)^length(d)
res = res/sum(res)
df = data.frame(k=k,val=res)
p6 = ggplot(df, aes(x=k, y=val))+
geom_line()+
ggtitle('distribution of posterior k')
print(p6)
print(k[which.max(res)])
rm(list=ls())
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
d = c(1.83,2.02,2.33,-2.79,2.07,2.02,-2.44,2.14,2.54,2.23)
k = (1:1000)/100
mu = 2.51
res = exp(k*sum(cos(d-mu))-k)/besselI(x = k, nu=0)^length(d)
res = res/sum(res)
df = data.frame(k=k,val=res)
p6 = ggplot(df, aes(k,val))+
geom_line()+
ggtitle('distribution of posterior k')+
print(p6)
reinstall_tinytex()
tinytex::install_tinytex()
x <-c(1,2,3,4)
t <- 2.2
4*(t-x)**2+(x-2.5)**2
4*(t-mean(x))**2+(x-2.5)**2
4*(t-mean(x))**2+sum((x-2.5)**2)
sum((x-t)**2)
x <-c(1,2,3,4)
t <- 2
4*(t-mean(x))**2+sum((x-2.5)**2)
sum((x-t)**2)
295+118.75
295+118.75+106.5
295+132+106.5
315+118.75+106.5
295+118.75+106.5
295+132+106.5
520.25+533.5+540.25+533.5+520.25+523.25
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
library('mvtnorm')
wdata <- read.table("WomenAtWork.dat", header = TRUE)
Probit <- 0
Covs <- c(2:8)
lambda <- 1
Nobs <- dim(wdata)[1]
y <- wdata$Work
X <- as.matrix(wdata[,Covs])
Xnames <- colnames(X)
Npar <- dim(X)[2]
mu <- as.matrix(rep(0,Npar))
Sigma <- (1/lambda)*diag(Npar)
LogPostLogistic <- function(betas,y,X,mu,Sigma){
linPred <- X%*%betas;
logLik <- sum( linPred*y - log(1 + exp(linPred)) );
#if (abs(logLik) == Inf) logLik = -20000; # Likelihood is not finite, stear the optimizer away from here!
logPrior <- dmvnorm(betas, mu, Sigma, log=TRUE);
return(logLik + logPrior)
}
LogPostProbit <- function(betas,y,X,mu,Sigma){
linPred <- X%*%betas;
SmallVal <- .Machine$double.xmin
logLik <- sum(y*log(pnorm(linPred)+SmallVal) + (1-y)*log(1-pnorm(linPred)+SmallVal) )
logPrior <- dmvnorm(betas, mu, Sigma, log=TRUE);
return(logLik + logPrior)
}
# Select the initial values for beta
initVal <- matrix(0,Npar,1)
if (Probit==1){
logPost = LogPostProbit;
} else{
logPost = LogPostLogistic;
}
opt <- optim(initVal,logPost,gr=NULL,y,X,mu,Sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
names(opt$par) <- Xnames # Naming the coefficient by covariates
approxPostStd <- sqrt(diag(-solve(opt$hessian))) # Computing approximate standard deviations.
names(approxPostStd) <- Xnames # Naming the coefficient by covariates
print('The posterior mode is:')
print(opt$par)
print('The approximate posterior standard deviation is:')
approxPostStd <- sqrt(diag(-solve(opt$hessian)))
print(approxPostStd)
child_feature_data <- as.data.frame(
mvtnorm::rmvnorm(n = 1000, mean = opt$par, sigma = -solve(opt$hessian))
)[,6]
CI_0_025 <- quantile(child_feature_data, probs = c(0.025,0.975))[1]
CI_0_975 <- quantile(child_feature_data, probs = c(0.025,0.975))[2]
interval <- c(CI_0_025,CI_0_975)
print('The 95% equal tail interval is :')
cat(interval)
situation <- c(1,20,12,8,43,0,2)
set.seed(123)
df <- as.data.frame(rmvnorm(n = 1000, mean = opt$par, sigma = -solve(opt$hessian)))
draw <- function(situation,df)
{
samples <<- as.data.frame(t(situation %*% t(df)))
res <- as.data.frame(1/(1+exp(-samples)))
colnames(res) <- "working_prob"
res$work <- ifelse(res$working_prob < 0.5, "not work", "work")
res$work_label <- ifelse(res$working_prob < 0.5, 0, 1)
res$nr <- c(1:nrow(res))
res_2b <<- res
}
draw(situation,df)
ggplot(data = res_2b, aes(x = working_prob)) +
geom_histogram(aes(y = ..density..),
colour = "black",
fill   = "white",
bins   = 40) +
geom_density(alpha = .2, fill = "#FF6666") +
ggtitle("posterior distribution of working probability") +
xlim(c(0,1))
library(ggplot2)
library(LaplacesDemon)
library(reshape2)
library(mvtnorm)
library(gridExtra)
situation <- c(1,20,12,8,43,0,2)
set.seed(123)
df <- as.data.frame(rmvnorm(n = 1000, mean = opt$par, sigma = -solve(opt$hessian)))
draw <- function(situation,df)
{
samples <<- as.data.frame(t(situation %*% t(df)))
res <- as.data.frame(1/(1+exp(-samples)))
colnames(res) <- "working_prob"
res$work <- ifelse(res$working_prob < 0.5, "not work", "work")
res$work_label <- ifelse(res$working_prob < 0.5, 0, 1)
res$nr <- c(1:nrow(res))
res_2b <<- res
}
draw(situation,df)
ggplot(data = res_2b, aes(x = working_prob)) +
geom_histogram(aes(y = ..density..),
colour = "black",
fill   = "white",
bins   = 40) +
geom_density(alpha = .2, fill = "#FF6666") +
ggtitle("posterior distribution of working probability") +
xlim(c(0,1))
situation <- c(1,20,12,8,43,0,2)
N_obs <- 11
draw <- function(situation,n,means,covar,n_obs)
{
betas <- rmvnorm(n,mean=means,sigma = covar)
situation <- as.matrix(situation)
samples <- betas%*%situation
prob <- exp(samples)/(1+exp(samples))
posterior <- sapply(prob,FUN=function(x){rbinom(1,n_obs,x)})
return(posterior)
}
posterior <- draw(situation,1000,opt$par,-solve(opt$hessian),N_obs)
hist(posterior,breaks = 8,freq = FALSE,main = "distribution for the number of working women")
rm(list=ls())
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
library(ggplot2)
library(LaplacesDemon)
library(reshape2)
library(mvtnorm)
library(gridExtra)
tempdata <- read.table("TempLambohov.txt",header = TRUE)
y <- tempdata$temp
# x = (beta0,beta1,beta2)
X <- cbind(1, tempdata$time, tempdata$time**2)
n_obs <- nrow(X)
mu0 <- c(-10, 100, -100)
omega0<- 0.02*diag(3)
v0 <- 3
sigma0 <- 2
N <- 20
coe_prior <- matrix(ncol = 3, nrow = N)
for (i in 1:N) {
#from L5 slides
sigma  <- LaplacesDemon::rinvchisq(1 ,v0, sigma0)
beta <- MASS::mvrnorm(1, mu0, sigma*solve(omega0))
coe_prior[i,1:3] <- beta
}
df <- as.data.frame(cbind(tempdata$time, X%*%t(coe_prior)))
cnames <- c("x")
for (i in 1:N) {
cnames[1+i] <- paste0("series_",i)
}
colnames(df) <- cnames
df <- melt(df, id.vars = "x")
p1a <- ggplot(df)+
geom_line(aes(x = x, y = value, color = variable)) +
geom_point(data = tempdata, aes(x = time, y = temp)) +
ggtitle("Results of original parameters") + ylab("Temperature") + xlab("Time")
p1a
lm1 <- lm(temp ~ time + I(time^2),data = tempdata)
summary(lm1)
tempdata <- read.table("TempLambohov.txt",header = TRUE)
y <- tempdata$temp
# x = (beta0,beta1,beta2)
X <- cbind(1, tempdata$time, tempdata$time**2)
n_obs <- nrow(X)
mu0 <- c(-11.927,103.418,-95.207)
omega0<- 0.025*diag(3)
v0 <- 3
sigma0 <- 0.1
N <- 20
coe_prior <- matrix(ncol = 3, nrow = N)
for (i in 1:N) {
#from L5 slides
sigma  <- LaplacesDemon::rinvchisq(1 ,v0, sigma0)
beta <- MASS::mvrnorm(1, mu0, sigma*solve(omega0))
coe_prior[i,1:3] <- beta
}
df <- as.data.frame(cbind(tempdata$time, X%*%t(coe_prior)))
cnames <- c("x")
for (i in 1:N) {
cnames[1+i] <- paste0("series_",i)
}
colnames(df) <- cnames
df <- melt(df, id.vars = "x")
p1a <- ggplot(df)+
geom_line(aes(x = x, y = value, color = variable)) +
geom_point(data = tempdata, aes(x = time, y = temp)) +
ggtitle("Change mean vector") + ylab("Temperature") + xlab("Date")
p1a
k <- 3 #  nr of regression coefficients
beta_hat <- solve(t(X)%*%X)%*%t(X)%*%y
mu_n <- solve(t(X)%*%X+omega0)%*%(t(X)%*%X%*%beta_hat+omega0%*%mu0)
omega_n  <- t(X) %*% X+omega0
v_n <- v0+n_obs
sigma_n <- (v0*sigma0+(t(y)%*%y+t(mu0)%*%omega0%*%mu0-t(mu_n)%*%omega_n%*% mu_n))/v_n
df1 <- as.data.frame(
mvtnorm::rmvt(n = 500, delta = mu_n, df = n_obs-k,
sigma = as.numeric(sigma_n) * solve(t(X) %*% X))
)
df2 <- LaplacesDemon::rinvchisq(n = 1000, v_n, sigma_n)
df <- cbind(df1, df2)
cnames <- c("beta0", "beta1", "beta2", "sigma")
colnames(df) <- cnames
ggplot(df,aes(beta0)) +
geom_histogram(aes(y = ..density..),
colour = "black",
fill   = "white",
bins   = 40) +
geom_density(alpha = .2, fill = "purple")
ggplot(df,aes(beta1)) +
geom_histogram(aes(y = ..density..),
colour = "black",
fill   = "white",
bins   = 40) +
geom_density(alpha = .2, fill = "purple")
ggplot(df,aes(beta2)) +
geom_histogram(aes(y = ..density..),
colour = "black",
fill   = "white",
bins   = 40) +
geom_density(alpha = .2, fill = "purple")
ggplot(df,aes(sigma)) +
geom_histogram(aes(y = ..density..),
colour = "black",
fill   = "white",
bins   = 40) +
geom_density(alpha = .2, fill = "purple")
df = df[,1:3]
column_median <- apply(df,2,median)
res1b <- column_median%*%t(X)
pre <- as.matrix(df) %*% t(X) # regression function
pre_interval <- data.frame(nrow = n_obs, nrow = 2)
colnames(pre_interval) <- c("i0.025","i0.975")
for(i in 1:n_obs){
data_t <- pre[,i]
pre_interval[i,] <- quantile(data_t, probs = c(0.025,0.975))
}
df1b <- cbind(tempdata, t(res1b), pre_interval)
ggplot(df1b) +
geom_point(aes(x = time, y = temp, color = "original data")) +
geom_line(aes(x = time, y = t(pred.1b), color = "median value"),size = 1) +
geom_line(aes(x = time, y = i0.025, color = "interval"), linetype = "dotted", size = 1.5) +
geom_line(aes(x = time, y = i0.975, color = "interval"), linetype = "dotted", size = 1.5) +
ggtitle('median with interval')+
ylab("Temperature") + xlab("Date")
df = df[,1:3]
column_median <- apply(df,2,median)
res1b <- column_median%*%t(X)
pre <- as.matrix(df) %*% t(X) # regression function
pre_interval <- data.frame(nrow = n_obs, nrow = 2)
colnames(pre_interval) <- c("i0.025","i0.975")
for(i in 1:n_obs){
data_t <- pre[,i]
pre_interval[i,] <- quantile(data_t, probs = c(0.025,0.975))
}
df1b <- cbind(tempdata, t(res1b), pre_interval)
ggplot(df1b) +
geom_point(aes(x = time, y = temp, color = "original data")) +
geom_line(aes(x = time, y = t(pred.1b), color = "median value"),size = 1) +
geom_line(aes(x = time, y = i0.025, color = "interval"), linetype = "dotted", size = 1.5) +
geom_line(aes(x = time, y = i0.975, color = "interval"), linetype = "dotted", size = 1.5) +
ggtitle('median with interval')+
ylab("Temperature") + xlab("Date")
df = df[,1:3]
column_median <- apply(df,2,median)
res1b <- column_median%*%t(X)
pre <- as.matrix(df) %*% t(X) # regression function
pre_interval <- data.frame(nrow = n_obs, nrow = 2)
colnames(pre_interval) <- c("i0.025","i0.975")
for(i in 1:n_obs){
data_t <- pre[,i]
pre_interval[i,] <- quantile(data_t, probs = c(0.025,0.975))
}
df1b <- cbind(tempdata, t(res1b), pre_interval)
ggplot(df1b) +
geom_point(aes(x = time, y = temp, color = "original data")) +
geom_line(aes(x = time, y = t(res1b), color = "median value"),size = 1) +
geom_line(aes(x = time, y = i0.025, color = "interval"), linetype = "dotted", size = 1.5) +
geom_line(aes(x = time, y = i0.975, color = "interval"), linetype = "dotted", size = 1.5) +
ggtitle('median with interval')+
ylab("Temperature") + xlab("Date")
maximum_pre <- c()
for(i in 1:365){
maximum_pre <- c(maximum_pre,max(pre[,i]))
}
df1c <- cbind(tempdata, t(res1b), pre_interval, maximum_pre)
ggplot(df1c) +
geom_point(aes(x = time, y = temp, color = "original data")) +
geom_line(aes(x = time, y = t(res1b),color = "pre in b"),size = 1) +
geom_line(aes(x = time, y = i0.025, color = "interval"), linetype = "dotted", size = 1.5) +
geom_line(aes(x = time, y = i0.975, color = "interval"), linetype = "dotted", size = 1.5) +
geom_line(aes(x = time,y = maximum_pre, color = "max_prein b"), linetype = "solid", size = 1)
library('mvtnorm')
wdata <- read.table("WomenAtWork.dat", header = TRUE)
Probit <- 0
Covs <- c(2:8)
lambda <- 1
Nobs <- dim(wdata)[1]
y <- wdata$Work
X <- as.matrix(wdata[,Covs])
Xnames <- colnames(X)
Npar <- dim(X)[2]
mu <- as.matrix(rep(0,Npar))
Sigma <- (1/lambda)*diag(Npar)
LogPostLogistic <- function(betas,y,X,mu,Sigma){
linPred <- X%*%betas;
logLik <- sum( linPred*y - log(1 + exp(linPred)) );
#if (abs(logLik) == Inf) logLik = -20000; # Likelihood is not finite, stear the optimizer away from here!
logPrior <- dmvnorm(betas, mu, Sigma, log=TRUE);
return(logLik + logPrior)
}
LogPostProbit <- function(betas,y,X,mu,Sigma){
linPred <- X%*%betas;
SmallVal <- .Machine$double.xmin
logLik <- sum(y*log(pnorm(linPred)+SmallVal) + (1-y)*log(1-pnorm(linPred)+SmallVal) )
logPrior <- dmvnorm(betas, mu, Sigma, log=TRUE);
return(logLik + logPrior)
}
# Select the initial values for beta
initVal <- matrix(0,Npar,1)
if (Probit==1){
logPost = LogPostProbit;
} else{
logPost = LogPostLogistic;
}
opt <- optim(initVal,logPost,gr=NULL,y,X,mu,Sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
names(opt$par) <- Xnames # Naming the coefficient by covariates
approxPostStd <- sqrt(diag(-solve(opt$hessian))) # Computing approximate standard deviations.
names(approxPostStd) <- Xnames # Naming the coefficient by covariates
print('The posterior mode is:')
print(opt$par)
print('The approximate posterior standard deviation is:')
approxPostStd <- sqrt(diag(-solve(opt$hessian)))
print(approxPostStd)
child_feature_data <- as.data.frame(
mvtnorm::rmvnorm(n = 1000, mean = opt$par, sigma = -solve(opt$hessian))
)[,6]
CI_0_025 <- quantile(child_feature_data, probs = c(0.025,0.975))[1]
CI_0_975 <- quantile(child_feature_data, probs = c(0.025,0.975))[2]
interval <- c(CI_0_025,CI_0_975)
print('The 95% equal tail interval is :')
cat(interval)
situation <- c(1,20,12,8,43,0,2)
set.seed(123)
df <- as.data.frame(rmvnorm(n = 1000, mean = opt$par, sigma = -solve(opt$hessian)))
draw <- function(situation,df)
{
samples <<- as.data.frame(t(situation %*% t(df)))
res <- as.data.frame(1/(1+exp(-samples)))
colnames(res) <- "working_prob"
res$work <- ifelse(res$working_prob < 0.5, "not work", "work")
res$work_label <- ifelse(res$working_prob < 0.5, 0, 1)
res$nr <- c(1:nrow(res))
res_2b <<- res
}
draw(situation,df)
ggplot(data = res_2b, aes(x = working_prob)) +
geom_histogram(aes(y = ..density..),
colour = "black",
fill   = "white",
bins   = 40) +
geom_density(alpha = .2, fill = "#FF6666") +
ggtitle("posterior distribution of working probability") +
xlim(c(0,1))
situation <- c(1,20,12,8,43,0,2)
N_obs <- 11
draw <- function(situation,n,means,covar,n_obs)
{
betas <- rmvnorm(n,mean=means,sigma = covar)
situation <- as.matrix(situation)
samples <- betas%*%situation
prob <- exp(samples)/(1+exp(samples))
posterior <- sapply(prob,FUN=function(x){rbinom(1,n_obs,x)})
return(posterior)
}
posterior <- draw(situation,1000,opt$par,-solve(opt$hessian),N_obs)
hist(posterior,breaks = 8,freq = FALSE,main = "working women distribution",xlab='number of working women',ylab = 'probability')
rm(list=ls())
setwd('E:\\courseMaterial\\732A73 bayesian\\Module 2')
