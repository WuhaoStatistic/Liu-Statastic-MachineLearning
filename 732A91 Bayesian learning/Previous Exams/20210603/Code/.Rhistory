plot(xGrid,mu)
quantile(mu, probs=c(0.05, 0.95))
abline(v=quantile(mu, c(0.05, 0.95))[1], col="red")
abline(v=quantile(mu, c(0.05, 0.95))[2], col="red")
# The intervals doesn't look accurate?
ytilde <- rep(0,N)
xtilde <- c(1, 0.4, 1, 1, 0, 0, 0)
for (i in 1:N){
ytilde[i] = sum(xtilde*Betas[i,]) + rnorm(n=1, mean = 0, sd =
sqrt(Sigma[i]))
}
hist(ytilde, main ="Predictive distribution of y", breaks=30)
ytilde <- rep(0,10000)
xtilde <- c(1, 0.4, 1, 1, 0, 0, 0)
for (i in 1:N){
ytilde[i] = sum(xtilde*Betas[i,]) + rnorm(n=1, mean = 0, sd =
sqrt(Sigma[i]))
}
hist(ytilde, main ="Predictive distribution of y", breaks=30)
ytilde <- rep(0,10000)
xtilde <- c(1, 0.4, 1, 1, 0, 0, 0)
for (i in 1:10000){
ytilde[i] = sum(xtilde*Betas[i,]) + rnorm(n=1, mean = 0, sd =
sqrt(Sigma[i]))
}
hist(ytilde, main ="Predictive distribution of y", breaks=30)
38*60/100
n <- 100
s <- 38
f <- n - s
postA <- pbeta(0.4, s + 16, f + 24, lower.tail = F)
postA
theta <- seq(0, 1, 0.005556)
#plot(x = theta, y = 1 - postA, type = "l", xlab = "theta", ylab = "Posterior")
plot(x = theta, y = 1 - postA, type = "l", xlab = "theta", ylab = "Posterior")
rep(1/3,3) * 60
Dirichlet <- function(nDraws,y,alpha){
x <- vapply(alpha + y, function(alpha){
rgamma(n=nDraws,alpha,1)
},FUN.VALUE = numeric(nDraws))
z <- apply(x,1,function(x) x/sum(x))
z <- t(z)
return(z)
}
# a bit unsure if prior should only be 1/3 1/3 1/3
alpha <- rep(1/3,3) * 60
A <- 38
B <- 27
C <- 35
y <- c(38,27,35)
set.seed(12345)
sim_dirichlet <- Dirichlet(nDraws = 1e4,y = y,alpha = alpha )
# A>C
prob_AgeC<- mean(sim_dirichlet[,1] >sim_dirichlet[,3])
prob_AgeC
31.25/40
32/40
0.8*20
0.78125*20
plot(theta_grid,PostDens,main="Posterior distribution",xlab="theta", ylab="")
plot(theta_grid,PostDens,col="blue",main="Posterior distribution",xlab="theta", ylab="")
lines(theta_grid,dnorm(theta_grid,mean = OptRes$par,sd = sqrt(-1/OptRes$hessian)),col="red")
legend(1, 95, legend=c("Line 1", "Line 2"),
col=c("red", "blue"), lty=1:2, cex=0.8)
legend(legend=c("Line 1", "Line 2"),col=c("red", "blue"))
legend(1,legend=c("Line 1", "Line 2"),col=c("red", "blue"))
legend("topleft", legend=c("Line 1", "Line 2"),
col=c("red", "blue"), lty=1:2, cex=0.8)
legend("topleft", legend=c("Approximation", "Exact"), col=c("red", "blue"), lty=1:2, cex=0.8)
plot(density(Diff),main="Posterior distribution",xlab="Beta_5 - Beta_6", ylab="")
Effect_B <- Betas[,2] + Betas[,6]
Effect_C <- Betas[,2] + Betas[,7]
Diff <- Effect_B - Effect_C
plot(density(Diff),main="Posterior distribution",xlab="Beta_5 - Beta_6", ylab="")
plot(x1_grid,Mu_draws[,1],"n");lines(x1_grid,Mu_draws[,1],col="blue",main="90 % posterior probability intervals as a function of x1",xlab="x1", ylab="")
lines(x1_grid,Mu_draws[,2],col="blue")
plot(x1_grid,Mu_draws[,1],"n",main="90 % posterior probability intervals as a function of x1",
xlab="x1", ylab="")
lines(x1_grid,Mu_draws[,1],col="blue")
lines(x1_grid,Mu_draws[,2],col="blue")
plot(x1_grid,Mu_draws[,1],"n",main="90 % posterior probability intervals as a function of x1",
xlab="x1", ylab="",ylim=c(-2,5))
lines(x1_grid,Mu_draws[,1],col="blue")
lines(x1_grid,Mu_draws[,2],col="blue")
plot(x1_grid,Mu_draws[,1],"n",main="90 % posterior probability intervals as a function of x1",
xlab="x1", ylab="",ylim=c(-2,4))
lines(x1_grid,Mu_draws[,1],col="blue")
lines(x1_grid,Mu_draws[,2],col="blue")
numeric(7)
n=13
alfa = 1+n
beta = 0.5+2.8
estimate = (alfa-1)/beta
LogPostGamma <- function(theta,x){
return(dgamma(x,shape = alfa ,rate = beta,log = TRUE))
}
width = 0.01
Xgrid = seq(0.1,10,width)
ygrid = LogPostGamma(estimate,Xgrid)
postgrid = (1/width)*exp(ygrid)/sum(exp(ygrid))
plot(Xgrid,postgrid)
n=13
alfa = 1+n
beta = 0.5+2.8
estimate = (alfa-1)/beta
LogPostGamma2 <- function(theta,x){
loglik = sum((log(2*theta*x)-theta*x^2))
logprior = dgamma(theta,shape = 1,rate = 0.5, log = TRUE)
return(loglik+logprior)
}
#postgrid = (1/width)*exp(ygrid2)/sum(exp(ygrid2))
#plot(Xgrid,postgrid)
initVal = estimate;
optRes <- optim(par = initVal, fn  = LogPostGamma2,lower = 0.1, gr = NULL, as.matrix(Xgrid), method = c("L-BFGS-B"),control = list(fnscale = -1), hessian = TRUE)
postMean <- exp(optRes$par) # This is the mean
sd <- sqrt(exp(-solve(optRes$hessian)))
ygrid2 = dnorm(Xgrid,mean = postMean,sd = sd, log = TRUE)
postgrid2 = (1/width)*exp(ygrid2)/sum(exp(ygrid2))
{
par(mfrow=c(2,1))
plot(Xgrid,dnorm(Xgrid,mean = postMean,sd = sd),col = "blue")
lines(Xgrid,postgrid,col = "red")
}
```
result
initVal = estimate;
optRes <- optim(par = initVal, fn  = LogPostGamma2,lower = 0.1, gr = NULL, as.matrix(Xgrid), method = c("L-BFGS-B"),control = list(fnscale = -1), hessian = TRUE)
postMean <- exp(optRes$par) # This is the mean
sd <- sqrt(exp(-solve(optRes$hessian)))
ygrid2 = dnorm(Xgrid,mean = postMean,sd = sd, log = TRUE)
postgrid2 = (1/width)*exp(ygrid2)/sum(exp(ygrid2))
{
par(mfrow=c(2,1))
plot(Xgrid,dnorm(Xgrid,mean = postMean,sd = sd),col = "blue")
lines(Xgrid,postgrid,col = "red")
}
initVal = estimate;
optRes <- optim(par = initVal, fn  = LogPostGamma2,lower = 0.1, gr = NULL, as.matrix(Xgrid), method = c("L-BFGS-B"),control = list(fnscale = -1), hessian = TRUE)
postMean <- exp(optRes$par) # This is the mean
sd <- sqrt(exp(-solve(optRes$hessian)))
ygrid2 = dnorm(Xgrid,mean = postMean,sd = sd, log = TRUE)
postgrid2 = (1/width)*exp(ygrid2)/sum(exp(ygrid2))
{
par(mfrow=c(2,1))
plot(Xgrid,dnorm(Xgrid,mean = postMean,sd = sd),col = "blue")
lines(Xgrid,postgrid,col = "red")
}
rep(1,nPara)
nPara <- dim(X)[2]
# Setting up the prior
Omega_0 <- diag(nPara)*4
mu_0 <- as.vector(rep(1,nPara))
Omega_0
mu_0
knitr::opts_chunk$set(echo = TRUE)
eta(alpha+s,f+24)/beta(alpha,24)
beta(alpha+s,f+24)/beta(alpha,24)
alpha+s
alpha
alpha <- 16
beta(alpha+s,f+24)/beta(alpha,24)
n<- 100
alpha<-16
beta<-24
s1<-38
s2<-27
s3<-35
f1<-n-s1
f2<-n-s2
f3<-n-s3
c(1 - pbeta(0.4,s1+alpha,f1+beta))
```
```{r}
theta<- 1 - pbeta(0.4,s1+alpha,f1+beta)
new_x<- (1-theta)/theta
quantile(new_x, c(0.025,0.975))
theta<- 1 - pbeta(0.4,s1+alpha,f1+beta)
new_x<- (1-theta)/theta
quantile(new_x, c(0.025,0.975))
13/3.3
log_post<- function(theta, x){
log_lik<- sum(-2*log(theta) + log(x) -(theta * x^2))
log_prior<- dexp(theta, rate=0.5, log=TRUE)
return(log_lik + log_prior)
}
thetaGrid <- seq(0.01,4,0.001)
count<- 0
x<-2.8
post_out<- rep(0, length(thetaGrid))
for(theta in thetaGrid){
count<- count+1
post_out[count]<- log_post(theta, x)
}
plot(thetaGrid, post_out, type="l")
n<-13
sum_x2<- 2.8
alpha<-1
beta<-2
N <- 1000
inv_lambda <- rgamma(N,alpha+n,beta+sum_x2)
lambda <- 1/inv_lambda
dens <- density(lambda)
modes<- dens$x[which.max(dens$y)]
print(modes)
xgrid <- seq(0,10,length.out=1000)
k<-2
new_pdf <- function(x,k){
pdf <- k*x^(k-1)*exp(-x^k)
}
plot(xgrid,new_pdf(xgrid,k),col=2, type="l")
initVal <- 1
optRes = optim(initVal, log_post, gr=NULL, sum_x2, method=c("L-BFGS-B"),
lower = 0.1, control=list(fnscale=-1), hessian=TRUE)
postMean<-optRes$par
postCov<- -solve(optRes$hessian)
c(postMean, postCov)
plot(xgrid,new_pdf(xgrid,k),col=2, type="l")
lines(xgrid, dnorm(xgrid, mean=postMean, sd=sqrt(postCov)), col="blue")
x1Grid<- seq(-3.206571, 3.195369 , by=0.01)
Xpred<- cbind(1, x1Grid, 0.5,0,0,0,0)
n<-length(x1Grid)
predband<- matrix(0,n,2)
for(i in 1:n){
sample= Xpred[i,] * (Betas)+rnorm(10000, 0, Sigma)
predband=quantile(sample, probs=c(0.05,0.95))
}
predband
hist(Xpred[,2],50, freq=FALSE)
lines(density(predband), col="red")
xtilde<- c(1, 0.4,1,1,0,0.4,0)
ytilde<- rep(0, nIter)
for(i in 1:nIter){
ytilde[i]=sum(xtilde * Betas[i,])+rnorm(1,mean=0, sd=Sigma[i])
}
hist(ytilde, 50)
a0 = 16
b0 = 24
n = 100
s = 38
f = 62
post_alpha = a0 + s
post_beta = b0 + f
theta = c()
for(i in 1:10000){
theta[i] = rbeta(1, post_alpha, post_beta)
}
ProbA <- mean(theta>0.4)
print(ProbA)
plot(1:10000, 1-theta)
g = (1-theta)/theta
print(quantile(g, c(0.025, 0.975)))
plik1 <- function(theta){
dbinom(x = 38, size = n, prob = theta) *
dbeta(x = theta, shape1 = a0, shape2 = b0)
}
(MargLik1 <- integrate(f = plik1, lower = 0, upper = 1)$value)
mean_a = mean_b = mean_c = 1/3
n_prior = 60
# mean_a * n_prior = 1/3*60 = 20
alpha_a = alpha_b = alpha_c = 20
rand_a = rdirichlet(n_prior,20)
rand_b = rdirichlet(n_prior,20)
rand_c = rdirichlet(n_prior,20)
post_a = ddirichlet(rand_a, 20)
post_b = ddirichlet(rand_b, 20)
post_c = ddirichlet(rand_c, 20)
prob_d = mean(post_a>post_b)
print(prob_d)
x = 2.8
n = 13
LogPost <- function(thetas){
logLik <- n*log(thetas) - log(thetas%*% x);
logPrior <- dgamma(thetas, n+1, log=TRUE);
return(logLik + logPrior)
}
gridWidth <- 0.01
thetaGrid <- seq(0.01, 3, by = gridWidth)
logPostGrid <- rep(0,length(thetaGrid))
count <- 0
for (theta in thetaGrid){
count <- count + 1
logPostGrid[count] <-LogPost(theta)
}
# Given data
n=13
x<-sqrt(2.8/n)
# Log density function for the distribution
logfun <- function(x, theta = 1){
logdens <- 2*log(theta*x*exp(-theta*(x^2)))
return(logdens)
}
# Define the  posterior (likelihood x prior)
logPost <- function(theta = 1, data){
sum(logfun(x=data, theta)) + 1/2*exp(-theta/2) #using 2 a result
}
# Plot the posterior over a grid of theta values
gridWidth <- 0.01
thetaGrid <- seq(0.01, 3, by = gridWidth)
logPostGrid <- rep(0,length(thetaGrid))
count <- 0
for (theta in thetaGrid){
count <- count + 1
logPostGrid[count] <-logPost(theta, data = x)
}
# Taking exp() and normalizing
PostGrid <- (1/gridWidth)*exp(logPostGrid)/sum(exp(logPostGrid)) #(1/gridWidth) factor
plot(thetaGrid, PostGrid, type = "l", lwd = 2, ylim = c(0,1.1), main="Posterior distribution of theta",
ylab = "Density", xlab = expression(theta))
Data<-x
initVal <- mean(x)
optRes = optim(initVal, logPost, gr=NULL, Data, method=c("L-BFGS-B"),
lower = 0, control=list(fnscale=-1), hessian=TRUE)
# The Posterior mode
postMode <- optRes$par
# The Approximate posterior standard deviation
postStdev <- sqrt(-1/optRes$hessian)
plot(thetaGrid, PostGrid, type = "l", lwd = 2, ylim = c(0,1.1), main="Posterior distribution of theta",
ylab = "Density", xlab = expression(theta))
lines(thetaGrid, dnorm(thetaGrid, mean = postMode, sd = postStdev), col="red", lwd = 2)
legend(x = 1.8, y = 1, legend = c("True posterior", "Approximate posterior"),
col = c("black","red"), lty = c(1,1), lwd = c(2,2), cex = 0.8)
p = function(y)
{
return(beta(16+y,124-y)/beta(16,24))
}
beta(16+38,124-38)/beta(16,24)
n = 13
xi2 = 2.8
nDraws = 10000
## Function to calculate Log Posterior of theta
calc_log_post = function(nDraws, n,xi2){
draws = log(rgamma(nDraws,shape = n+1, rate = 1/(xi2+0.5)))
return(draws)
}
# Calculation of Log Posterior Theta
log_post_theta = calc_log_post(nDraws = nDraws, n = n, xi2 = xi2)
# Theta distribution
hist(log_post_theta,
main = "Posterior distribution of theta",
freq = F, breaks=100)
## Part a)
# Posterior Mean
res_mean = apply(Betas, FUN = mean, MARGIN = 2)
print("The Posterior Mean is", res_mean)
res_mean
res_int = apply(Betas, FUN = quantile, MARGIN = 2, probs = c(0.025,0.975))
res_int
n = 100
success_A = 38
fail_A = n = 38
alpha_a0 = 16
beta_a0 = 24
#we know that posterior of this model will be beta(alpha+s,beta+f)
post_theta_a = rbeta(10000,success_A+alpha_a0, fail_A+beta_a0)
prob_theta_A = 1 - pbeta(0.4,success_A+alpha_a0, fail_A+beta_a0)
cat("posterior probability that theta_A > 0.4 is ",prob_theta_A)
#we need to plot the posterior distrobution of 1 -theta_a
post_dist_of_1minustheta = 1 - post_theta_a
hist(post_dist_of_1minustheta)
ratio = post_dist_of_1minustheta / post_theta_a
equal_tail_ci = quantile(ratio,c(0.025,0.975))
dens_g = density(ratio)
plot(dens_g$y~dens_g$x)
abline(v = c(as.double(equal_tail_ci[1]),as.double(equal_tail_ci[2])), col = c("red","red"))
cat("95% equal tail interval is ",as.double(equal_tail_ci[1]),as.double(equal_tail_ci[2]))
marg = beta(success_A+alpha_a0, fail_A+beta_a0)/beta(alpha_a0, beta_a0)
cat("computed marginal liklihood is ", marg)
ya = 38 #number of occurence in A
yb = 27
yc = 35
a_a = a_b = a_c = 60/3 #num of imaginary occurance
#now let us simulate dirchlet dist # refered from code given in lectures
Dirichlet <- function(draws,y,a){
len <- length(a)
xDraws <- matrix(0,draws,len)
thetaDraws <- matrix(0,draws,len)
for (i in 1:len){
xDraws[,i] <- rgamma(draws,shape=a[i]+y[i],rate=1)
}
for (ii in 1:draws){
thetaDraws[ii,] <- xDraws[ii,]/sum(xDraws[ii,])
}
return(thetaDraws)
}
thetaDraws <- Dirichlet(10000,c(ya,yb,yc),c(a_a,a_b,a_c))
cat("posterior prob that theta_a > theta_c ",sum(thetaDraws[,1]>thetaDraws[,3])/10000)
1/5^2
BayesLinReg <- function(y, X, mu_0, Omega_0, v_0, sigma2_0, nIter){
# Direct sampling from a Gaussian linear regression with conjugate prior:
#
# beta | sigma2 ~ N(mu_0, sigma2*inv(Omega_0))
# sigma2 ~ Inv-Chi2(v_0,sigma2_0)
#
# INPUTS:
#   y - n-by-1 vector with response data observations
#   X - n-by-nCovs matrix with covariates, first column should be ones if you want an intercept.
#   mu_0 - prior mean for beta
#   Omega_0  - prior precision matrix for beta
#   v_0      - degrees of freedom in the prior for sigma2
#   sigma2_0 - location ("best guess") in the prior for sigma2
#   nIter - Number of samples from the posterior (iterations)
#
# OUTPUTS:
#   results$betaSample     - Posterior sample of beta.     nIter-by-nCovs matrix
#   results$sigma2Sample   - Posterior sample of sigma2.   nIter-by-1 vector
# Compute posterior hyperparameters
n = length(y) # Number of observations
nCovs = dim(X)[2] # Number of covariates
XX = t(X)%*%X
betaHat <- solve(XX,t(X)%*%y)
Omega_n = XX + Omega_0
mu_n = solve(Omega_n,XX%*%betaHat+Omega_0%*%mu_0)
v_n = v_0 + n
sigma2_n = as.numeric((v_0*sigma2_0 + ( t(y)%*%y + t(mu_0)%*%Omega_0%*%mu_0 - t(mu_n)%*%Omega_n%*%mu_n))/v_n)
invOmega_n = solve(Omega_n)
# The actual sampling
sigma2Sample = rep(NA, nIter)
betaSample = matrix(NA, nIter, nCovs)
for (i in 1:nIter){
# Simulate from p(sigma2 | y, X)
sigma2 = rinvchisq(n=1, df=v_n, scale = sigma2_n)
sigma2Sample[i] = sigma2
# Simulate from p(beta | sigma2, y, X)
beta_ = rmvnorm(n=1, mean = mu_n, sigma = sigma2*invOmega_n)
betaSample[i,] = beta_
}
return(results = list(sigma2Sample = sigma2Sample, betaSample=betaSample))
}
mu_0 = (rep(0,dim(X)[2]))
Omega_0 = 1/5^2
Omega_0 = Omega_0*diag(dim(X)[2])
v_0 = 1
sigma2_0 = 4
library(mvtnorm)
joint_post = BayesLinReg(y, X, mu_0, Omega_0, v_0, sigma2_0, 10000)
beta1_CI = quantile(joint_post$betaSample[,1],c(0.025,0.975))
beta2_CI = quantile(joint_post$betaSample[,2],c(0.025,0.975))
beta3_CI = quantile(joint_post$betaSample[,3],c(0.025,0.975))
beta4_CI = quantile(joint_post$betaSample[,4],c(0.025,0.975))
beta5_CI = quantile(joint_post$betaSample[,5],c(0.025,0.975))
beta6_CI = quantile(joint_post$betaSample[,6],c(0.025,0.975))
beta7_CI = quantile(joint_post$betaSample[,7],c(0.025,0.975))
y
# Reading the data from file
load(file = 'UniversityEntrance.RData')
mu_0 = (rep(0,dim(X)[2]))
Omega_0 = 1/5^2
Omega_0 = Omega_0*diag(dim(X)[2])
v_0 = 1
sigma2_0 = 4
library(mvtnorm)
joint_post = BayesLinReg(y, X, mu_0, Omega_0, v_0, sigma2_0, 10000)
beta1_CI = quantile(joint_post$betaSample[,1],c(0.025,0.975))
beta2_CI = quantile(joint_post$betaSample[,2],c(0.025,0.975))
beta3_CI = quantile(joint_post$betaSample[,3],c(0.025,0.975))
beta4_CI = quantile(joint_post$betaSample[,4],c(0.025,0.975))
beta5_CI = quantile(joint_post$betaSample[,5],c(0.025,0.975))
beta6_CI = quantile(joint_post$betaSample[,6],c(0.025,0.975))
beta7_CI = quantile(joint_post$betaSample[,7],c(0.025,0.975))
rbind(beta1_CI,beta2_CI,beta3_CI,beta4_CI,beta5_CI,beta6_CI,beta7_CI)
mean_beta1 = mean(joint_post$betaSample[,1])
mean_beta2 = mean(joint_post$betaSample[,2])
mean_beta3 = mean(joint_post$betaSample[,3])
mean_beta4 = mean(joint_post$betaSample[,4])
mean_beta5 = mean(joint_post$betaSample[,5])
mean_beta6 = mean(joint_post$betaSample[,6])
mean_beta7 = mean(joint_post$betaSample[,7])
rbind(mean_beta1,mean_beta2,mean_beta3,mean_beta4,mean_beta5,mean_beta6,mean_beta7)
#interpreting interval for beta1
hist(joint_post$betaSample[,2])
abline(v = c(beta2_CI[1],beta2_CI[2]))
abline(v = mean_beta2,col = "red")
sig2_median = median(joint_post$sigma2Sample)
sig2_median
id_b = which(X[,4] == 1)
id_c = which(X[,5] == 1)
sample = joint_post$betaSample[,2][id_b]
prob_int_school_b <- quantile(sample, prob = c(0.025, 0.975))
print('The 95% posterior probability interval is x1 in school b:')
print(prob_int_school_b )
samplec = joint_post$betaSample[,2][id_c]
prob_int_school_c <- quantile(samplec, prob = c(0.025, 0.975))
print('The 95% posterior probability interval is for x1 in school c:')
print(prob_int_school_c )
#x_new = c(1,grid,0.5,0,0,0,0)
x1_grid = seq(min(X[,2]),max(X[,2]), 0.01)
n = length(x1_grid)
expected <- function(grid){
X = cbind(rep(1,length(x1_grid)),x1_grid,rep(0.5,length(x1_grid)),rep(0,length(x1_grid)),rep(0,length(x1_grid)),rep(0,length(x1_grid)),rep(0,length(x1_grid)))
predbands = matrix(0,n,2)
for(i in 1:n){
samps = X[i,]%*%t(joint_post$betaSample)
predbands[i,] = quantile(samps,probs=c(.05,.95))
}
return( predbands=predbands)
}
pred <- expected(x1_grid)
plot(X[,2],y,type='p',
xlab="x1",ylab="y",main="Predictive bands")
lines(grid,pred[,1],col=2)
lines(grid,pred[,2],col=2)
y
x
grid
pred[,1]
plot(X[,2],y,type='p',
xlab="x1",ylab="y",main="Predictive bands")
lines(x1_grid,pred[,1],col=2)
lines(x1_grid,pred[,2],col=2)
x_new = c(1,0.4,1,1,0,0.4,0)
y = t(colMeans(joint_post$betaSample)) %*% x_new + rnorm(1,0,sqrt(sig2_median))
y
