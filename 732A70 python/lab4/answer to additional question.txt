[ ] In what way did you "clean up" or divide up the text into words (in the program; the text files should be left
unaffected)? This does not have to be perfect in any sense, but it should at least avoid counting "lord",
"Lord" and "lord." as different words.

I use regression expression to move everything(numbers, punctuation and all the other signs like @#$%^&*) except English letters out of the string.
And then I use the builtin function splitto divide the text into words. 


[ ] Which data structures have you used (such as lists, tuples, dictionaries, sets, ...)? Why does that choice
make sense? You do not have to do any extensive research on the topics, or try to find exotic modern data
structures, but you should reflect on which of the standard data types (or variants thereof) make sense. If
you have tried some other solution and updated your code later on, feel free to discuss the effects!

After split process we will have the text in the list whose elements are every words.
When I find the unique words, I use set() function to change list into a set.
When I calculate the letter frequency, I pre-build a dictionary containing 26 letters to accelerate this process.
When I summary the most common follow words, I use list and tuple(generated by zip) to record the data.